{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API and Callbacks\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, SimpleRNN, Input, Concatenate\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Same as California Pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and split into training, validation and test set\n",
    "housing = fetch_california_housing()\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                housing.data, housing.target)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "                                x_train, y_train)\n",
    "\n",
    "# check data dimensions\n",
    "x_train.shape\n",
    "\n",
    "# scale data\n",
    "scl = StandardScaler()\n",
    "x_train = scl.fit_transform(x_train)\n",
    "x_val = scl.transform(x_val)\n",
    "x_test = scl.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple inputs network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9c0750d3aadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;31m# A Network does not create weights of its own, thus it is already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m       \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m       if len(layer._inbound_nodes) > 1 or (\n\u001b[1;32m   1333\u001b[0m           layer._inbound_nodes and layer._inbound_nodes[0].inbound_layers):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape = [5], name='wide_input')\n",
    "input_B = Input(shape = [6], name='deep_input')\n",
    "hidden1 = Dense(50, activation='relu')(input_B)\n",
    "hidden2 = Dense(50, activation='relu')(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "output = Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs=[output])\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'sgd')\n",
    "keras.utils.plot_model(model, \"multi_inputs_model.png\", show_shapes=True)\n",
    "model.summary()\n",
    "\n",
    "# split data into two groups, one for each input\n",
    "# dataframe has dimensions: (11610, 8)\n",
    "x_train_A, x_train_B = x_train[:,:5], x_train[:,2:]\n",
    "x_val_A, x_val_B = x_val[:,:5], x_val[:,2:]\n",
    "x_test_A, x_test_B = x_test[:,:5], x_test[:,2:]\n",
    "\n",
    "history = model.fit((x_train_A, x_train_B), y_train, epochs=50, \n",
    "                    validation_data=((x_val_A, x_val_B), y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple outputs network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 50)           350         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 50)           2550        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 55)           0           wide_input[0][0]                 \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            56          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            51          dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,007\n",
      "Trainable params: 3,007\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/50\n",
      "11610/11610 [==============================] - 1s 60us/step - loss: 0.9631 - main_output_loss: 0.8314 - aux_output_loss: 2.1466 - val_loss: 0.8700 - val_main_output_loss: 0.7269 - val_aux_output_loss: 2.3504\n",
      "Epoch 2/50\n",
      "11610/11610 [==============================] - 1s 48us/step - loss: 0.5267 - main_output_loss: 0.4573 - aux_output_loss: 1.1550 - val_loss: 1.7180 - val_main_output_loss: 1.8007 - val_aux_output_loss: 1.7760\n",
      "Epoch 3/50\n",
      "11610/11610 [==============================] - 1s 52us/step - loss: 0.5134 - main_output_loss: 0.4649 - aux_output_loss: 0.9490 - val_loss: 1.0347 - val_main_output_loss: 1.0540 - val_aux_output_loss: 1.2353\n",
      "Epoch 4/50\n",
      "11610/11610 [==============================] - 1s 58us/step - loss: 0.4500 - main_output_loss: 0.4108 - aux_output_loss: 0.8022 - val_loss: 0.7581 - val_main_output_loss: 0.7409 - val_aux_output_loss: 1.1121\n",
      "Epoch 5/50\n",
      "11610/11610 [==============================] - 1s 55us/step - loss: 0.4326 - main_output_loss: 0.4026 - aux_output_loss: 0.7020 - val_loss: 0.5014 - val_main_output_loss: 0.4852 - val_aux_output_loss: 0.6954\n",
      "Epoch 6/50\n",
      "11610/11610 [==============================] - 1s 52us/step - loss: 0.4149 - main_output_loss: 0.3903 - aux_output_loss: 0.6358 - val_loss: 0.4225 - val_main_output_loss: 0.3975 - val_aux_output_loss: 0.6494\n",
      "Epoch 7/50\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.4188 - main_output_loss: 0.3986 - aux_output_loss: 0.6009 - val_loss: 0.4476 - val_main_output_loss: 0.4312 - val_aux_output_loss: 0.6216\n",
      "Epoch 8/50\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.3964 - main_output_loss: 0.3769 - aux_output_loss: 0.5723 - val_loss: 0.4698 - val_main_output_loss: 0.4606 - val_aux_output_loss: 0.5980\n",
      "Epoch 9/50\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.3885 - main_output_loss: 0.3705 - aux_output_loss: 0.5520 - val_loss: 0.4651 - val_main_output_loss: 0.4588 - val_aux_output_loss: 0.5708\n",
      "Epoch 10/50\n",
      "11610/11610 [==============================] - 1s 67us/step - loss: 0.3817 - main_output_loss: 0.3648 - aux_output_loss: 0.5336 - val_loss: 0.3890 - val_main_output_loss: 0.3698 - val_aux_output_loss: 0.5622\n",
      "Epoch 11/50\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.3747 - main_output_loss: 0.3586 - aux_output_loss: 0.5211 - val_loss: 0.3840 - val_main_output_loss: 0.3651 - val_aux_output_loss: 0.5551\n",
      "Epoch 12/50\n",
      "11610/11610 [==============================] - 1s 54us/step - loss: 0.3733 - main_output_loss: 0.3580 - aux_output_loss: 0.5103 - val_loss: 0.3852 - val_main_output_loss: 0.3671 - val_aux_output_loss: 0.5508\n",
      "Epoch 13/50\n",
      "11610/11610 [==============================] - 1s 61us/step - loss: 0.3688 - main_output_loss: 0.3541 - aux_output_loss: 0.5018 - val_loss: 0.3739 - val_main_output_loss: 0.3561 - val_aux_output_loss: 0.5346\n",
      "Epoch 14/50\n",
      "11610/11610 [==============================] - 1s 69us/step - loss: 0.3634 - main_output_loss: 0.3492 - aux_output_loss: 0.4905 - val_loss: 0.3915 - val_main_output_loss: 0.3787 - val_aux_output_loss: 0.5225\n",
      "Epoch 15/50\n",
      "11610/11610 [==============================] - 1s 58us/step - loss: 0.3751 - main_output_loss: 0.3629 - aux_output_loss: 0.4852 - val_loss: 0.3842 - val_main_output_loss: 0.3704 - val_aux_output_loss: 0.5181\n",
      "Epoch 16/50\n",
      "11610/11610 [==============================] - 1s 51us/step - loss: 0.3594 - main_output_loss: 0.3465 - aux_output_loss: 0.4748 - val_loss: 0.3766 - val_main_output_loss: 0.3617 - val_aux_output_loss: 0.5163\n",
      "Epoch 17/50\n",
      "11610/11610 [==============================] - 1s 51us/step - loss: 0.3539 - main_output_loss: 0.3415 - aux_output_loss: 0.4662 - val_loss: 0.4030 - val_main_output_loss: 0.3962 - val_aux_output_loss: 0.4915\n",
      "Epoch 18/50\n",
      "11610/11610 [==============================] - 1s 51us/step - loss: 0.3535 - main_output_loss: 0.3417 - aux_output_loss: 0.4588 - val_loss: 0.3580 - val_main_output_loss: 0.3440 - val_aux_output_loss: 0.4849\n",
      "Epoch 19/50\n",
      "11610/11610 [==============================] - 1s 67us/step - loss: 0.3468 - main_output_loss: 0.3350 - aux_output_loss: 0.4530 - val_loss: 0.3583 - val_main_output_loss: 0.3450 - val_aux_output_loss: 0.4792\n",
      "Epoch 20/50\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.3480 - main_output_loss: 0.3367 - aux_output_loss: 0.4487 - val_loss: 0.3750 - val_main_output_loss: 0.3648 - val_aux_output_loss: 0.4783\n",
      "Epoch 21/50\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.3415 - main_output_loss: 0.3305 - aux_output_loss: 0.4425 - val_loss: 0.3857 - val_main_output_loss: 0.3739 - val_aux_output_loss: 0.5058\n",
      "Epoch 22/50\n",
      "11610/11610 [==============================] - 1s 56us/step - loss: 0.3407 - main_output_loss: 0.3300 - aux_output_loss: 0.4364 - val_loss: 0.4204 - val_main_output_loss: 0.4203 - val_aux_output_loss: 0.4669\n",
      "Epoch 23/50\n",
      "11610/11610 [==============================] - 1s 62us/step - loss: 0.3372 - main_output_loss: 0.3266 - aux_output_loss: 0.4331 - val_loss: 0.4743 - val_main_output_loss: 0.4816 - val_aux_output_loss: 0.4943\n",
      "Epoch 24/50\n",
      "11610/11610 [==============================] - 1s 59us/step - loss: 0.3347 - main_output_loss: 0.3243 - aux_output_loss: 0.4284 - val_loss: 0.4096 - val_main_output_loss: 0.4093 - val_aux_output_loss: 0.4538\n",
      "Epoch 25/50\n",
      "11610/11610 [==============================] - 1s 67us/step - loss: 0.3353 - main_output_loss: 0.3252 - aux_output_loss: 0.4247 - val_loss: 0.3539 - val_main_output_loss: 0.3439 - val_aux_output_loss: 0.4499\n",
      "Epoch 26/50\n",
      "11610/11610 [==============================] - 1s 57us/step - loss: 0.3309 - main_output_loss: 0.3209 - aux_output_loss: 0.4201 - val_loss: 0.3677 - val_main_output_loss: 0.3613 - val_aux_output_loss: 0.4426\n",
      "Epoch 27/50\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.3307 - main_output_loss: 0.3209 - aux_output_loss: 0.4186 - val_loss: 0.3612 - val_main_output_loss: 0.3518 - val_aux_output_loss: 0.4499\n",
      "Epoch 28/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3305 - main_output_loss: 0.3212 - aux_output_loss: 0.4153 - val_loss: 0.3500 - val_main_output_loss: 0.3403 - val_aux_output_loss: 0.4411\n",
      "Epoch 29/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3280 - main_output_loss: 0.3188 - aux_output_loss: 0.4118 - val_loss: 0.3656 - val_main_output_loss: 0.3585 - val_aux_output_loss: 0.4420\n",
      "Epoch 30/50\n",
      "11610/11610 [==============================] - 1s 46us/step - loss: 0.3268 - main_output_loss: 0.3175 - aux_output_loss: 0.4097 - val_loss: 0.4038 - val_main_output_loss: 0.4052 - val_aux_output_loss: 0.4331\n",
      "Epoch 31/50\n",
      "11610/11610 [==============================] - 1s 45us/step - loss: 0.3269 - main_output_loss: 0.3179 - aux_output_loss: 0.4075 - val_loss: 0.3371 - val_main_output_loss: 0.3266 - val_aux_output_loss: 0.4340\n",
      "Epoch 32/50\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3284 - main_output_loss: 0.3198 - aux_output_loss: 0.4065 - val_loss: 0.3873 - val_main_output_loss: 0.3808 - val_aux_output_loss: 0.4735\n",
      "Epoch 33/50\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3260 - main_output_loss: 0.3170 - aux_output_loss: 0.4056 - val_loss: 0.3592 - val_main_output_loss: 0.3499 - val_aux_output_loss: 0.4530\n",
      "Epoch 34/50\n",
      "11610/11610 [==============================] - 1s 43us/step - loss: 0.3227 - main_output_loss: 0.3140 - aux_output_loss: 0.4008 - val_loss: 0.3441 - val_main_output_loss: 0.3347 - val_aux_output_loss: 0.4318\n",
      "Epoch 35/50\n",
      "11610/11610 [==============================] - 1s 48us/step - loss: 0.3212 - main_output_loss: 0.3125 - aux_output_loss: 0.3990 - val_loss: 0.4649 - val_main_output_loss: 0.4734 - val_aux_output_loss: 0.4705\n",
      "Epoch 36/50\n",
      "11610/11610 [==============================] - 1s 52us/step - loss: 0.3229 - main_output_loss: 0.3149 - aux_output_loss: 0.3961 - val_loss: 0.6151 - val_main_output_loss: 0.6413 - val_aux_output_loss: 0.4430\n",
      "Epoch 37/50\n",
      "11610/11610 [==============================] - 1s 61us/step - loss: 0.3261 - main_output_loss: 0.3182 - aux_output_loss: 0.3980 - val_loss: 0.3938 - val_main_output_loss: 0.3918 - val_aux_output_loss: 0.4517\n",
      "Epoch 38/50\n",
      "11610/11610 [==============================] - 1s 43us/step - loss: 0.3184 - main_output_loss: 0.3099 - aux_output_loss: 0.3946 - val_loss: 0.4093 - val_main_output_loss: 0.4133 - val_aux_output_loss: 0.4225\n",
      "Epoch 39/50\n",
      "11610/11610 [==============================] - 1s 45us/step - loss: 0.3189 - main_output_loss: 0.3107 - aux_output_loss: 0.3938 - val_loss: 0.3871 - val_main_output_loss: 0.3843 - val_aux_output_loss: 0.4445\n",
      "Epoch 40/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3170 - main_output_loss: 0.3088 - aux_output_loss: 0.3909 - val_loss: 0.3541 - val_main_output_loss: 0.3484 - val_aux_output_loss: 0.4199\n",
      "Epoch 41/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3167 - main_output_loss: 0.3085 - aux_output_loss: 0.3896 - val_loss: 0.4012 - val_main_output_loss: 0.4012 - val_aux_output_loss: 0.4427\n",
      "Epoch 42/50\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3147 - main_output_loss: 0.3067 - aux_output_loss: 0.3867 - val_loss: 0.3624 - val_main_output_loss: 0.3576 - val_aux_output_loss: 0.4246\n",
      "Epoch 43/50\n",
      "11610/11610 [==============================] - 1s 45us/step - loss: 0.3175 - main_output_loss: 0.3099 - aux_output_loss: 0.3861 - val_loss: 0.5319 - val_main_output_loss: 0.5494 - val_aux_output_loss: 0.5062\n",
      "Epoch 44/50\n",
      "11610/11610 [==============================] - 1s 48us/step - loss: 0.3203 - main_output_loss: 0.3129 - aux_output_loss: 0.3882 - val_loss: 0.6971 - val_main_output_loss: 0.7379 - val_aux_output_loss: 0.5709\n",
      "Epoch 45/50\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: 0.3207 - main_output_loss: 0.3132 - aux_output_loss: 0.3879 - val_loss: 0.6300 - val_main_output_loss: 0.6759 - val_aux_output_loss: 0.4161\n",
      "Epoch 46/50\n",
      "11610/11610 [==============================] - 1s 43us/step - loss: 0.3149 - main_output_loss: 0.3072 - aux_output_loss: 0.3851 - val_loss: 0.7307 - val_main_output_loss: 0.7686 - val_aux_output_loss: 0.6500\n",
      "Epoch 47/50\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.3182 - main_output_loss: 0.3109 - aux_output_loss: 0.3848 - val_loss: 0.4533 - val_main_output_loss: 0.4641 - val_aux_output_loss: 0.4281\n",
      "Epoch 48/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3135 - main_output_loss: 0.3060 - aux_output_loss: 0.3812 - val_loss: 0.4445 - val_main_output_loss: 0.4545 - val_aux_output_loss: 0.4259\n",
      "Epoch 49/50\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3158 - main_output_loss: 0.3085 - aux_output_loss: 0.3818 - val_loss: 0.4598 - val_main_output_loss: 0.4744 - val_aux_output_loss: 0.4122\n",
      "Epoch 50/50\n",
      "11610/11610 [==============================] - 1s 58us/step - loss: 0.3094 - main_output_loss: 0.3018 - aux_output_loss: 0.3771 - val_loss: 0.4961 - val_main_output_loss: 0.5116 - val_aux_output_loss: 0.4464\n"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape = [5], name='wide_input')\n",
    "input_B = Input(shape = [6], name='deep_input')\n",
    "hidden1 = Dense(50, activation='relu')(input_B)\n",
    "hidden2 = Dense(50, activation='relu')(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "main_output = Dense(1, name='main_output')(concat)\n",
    "aux_output = Dense(1, name='aux_output')(hidden2)\n",
    "model2 = keras.Model(inputs = [input_A, input_B], outputs=[main_output, aux_output])\n",
    "\n",
    "model2.compile(loss = ['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer = 'sgd')\n",
    "keras.utils.plot_model(model2, \"multi_outputs_model.png\", show_shapes=True)\n",
    "model2.summary()\n",
    "\n",
    "history = model2.fit([x_train_A, x_train_B], [y_train, y_train], epochs=50, \n",
    "                    validation_data=([x_val_A, x_val_B], [y_val, y_val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that When evaluating the model, the loss is split into total, main and auxiliary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 23us/step\n",
      "Total MSE: 0.4038230770318083 \n",
      " Main MSE: 0.3991163372993469 \n",
      " Aux MSE: 0.4355330169200897\n",
      "Main y_preds: [[1.6943412]\n",
      " [1.4466107]\n",
      " [1.9087393]\n",
      " [2.3763099]\n",
      " [5.0115895]] \n",
      " Aux y_preds: [[1.3439986]\n",
      " [1.564224 ]\n",
      " [1.8508682]\n",
      " [2.3151948]\n",
      " [4.2783275]]\n"
     ]
    }
   ],
   "source": [
    "total_mse, main_mse, aux_mse = model2.evaluate(\n",
    "                    [x_test_A, x_test_B], [y_test, y_test])\n",
    "print(f'Total MSE: {total_mse} \\n Main MSE: {main_mse} \\n Aux MSE: {aux_mse}')\n",
    "\n",
    "y_preds_main, y_preds_aux = model2.predict([x_test_A[:5], x_test_B[:5]])\n",
    "print(f'Main y_preds: {y_preds_main} \\n Aux y_preds: {y_preds_aux}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Dense(50, activation='relu', input_shape = x_train.shape[1:]),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Checkpointing: model can be saved during or after training to be restored at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_model.h5', save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Early Stopping: can be used to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) TensorBoard: can be used to keep track of training performances in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.curdir, 'logs')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train the model with callbacks by providing them as argument to the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.7197 - val_loss: 1.1657\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 36us/step - loss: 0.4221 - val_loss: 0.8961\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.3901 - val_loss: 0.5033\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3726 - val_loss: 0.5361\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.3641 - val_loss: 0.4756\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3545 - val_loss: 1.1658\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 51us/step - loss: 0.3576 - val_loss: 0.8845\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 47us/step - loss: 0.3498 - val_loss: 0.5812\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 55us/step - loss: 0.3414 - val_loss: 0.3483\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.3372 - val_loss: 0.3658\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3339 - val_loss: 0.3499\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.3330 - val_loss: 0.3442\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.3275 - val_loss: 0.3502\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.3244 - val_loss: 0.3476\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 39us/step - loss: 0.3238 - val_loss: 0.3318\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3205 - val_loss: 0.3624\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.3182 - val_loss: 0.3761\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 40us/step - loss: 0.3146 - val_loss: 0.4065\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3160 - val_loss: 0.3463\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 42us/step - loss: 0.3129 - val_loss: 0.3929\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.3091 - val_loss: 0.3969\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.3070 - val_loss: 0.3982\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 46us/step - loss: 0.3048 - val_loss: 0.3193\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 51us/step - loss: 0.3033 - val_loss: 0.3185\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 46us/step - loss: 0.3010 - val_loss: 0.4579\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 41us/step - loss: 0.3003 - val_loss: 0.4156\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.3018 - val_loss: 0.3940\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.2995 - val_loss: 0.6943\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.2962 - val_loss: 0.5617\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 43us/step - loss: 0.2988 - val_loss: 0.5131\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 44us/step - loss: 0.2959 - val_loss: 0.5640\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 47us/step - loss: 0.2984 - val_loss: 0.4737\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 49us/step - loss: 0.2924 - val_loss: 0.4637\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 1s 50us/step - loss: 0.2918 - val_loss: 0.3188\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer = 'sgd')\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val),\n",
    "                    callbacks=[checkpoint_cb, earlystop_cb])\n",
    "model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
