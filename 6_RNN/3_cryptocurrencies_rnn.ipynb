{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cryptocurrencies using RNNs\n",
    "The problem can be approached from two different perspectives:\n",
    "* Classification (e.g. buy, hold, sell)\n",
    "* Regression (future price)"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Lorenzo-Giardi/tf-keras/blob/master/6_RNN/3_cryptocurrencies_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, BatchNormalization, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60 # last minutes to use as feature\n",
    "FUTURE_PERIOD_PREDICT = 3 # period over which to make the prediction\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f'{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        low       high       open      close      volume\n",
      "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
      "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
      "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
      "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
      "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978\n"
     ]
    }
   ],
   "source": [
    "col_names = ['time', 'low', 'high', 'open', 'close', 'volume']\n",
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\", names = col_names)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "\n",
      "            ETH-USD_close  ETH-USD_volume  BCH-USD_close  BCH-USD_volume  \n",
      "time                                                                      \n",
      "1528968660            NaN             NaN     871.719971        5.675361  \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577  \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300  \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862  \n",
      "1528968900      486.00000       77.355759     870.000000        1.680500  \n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "ratios = ['BTC-USD', 'LTC-USD', 'ETH-USD', 'BCH-USD']\n",
    "for ratio in ratios:\n",
    "    # read CSV from path\n",
    "    df_path = f'crypto_data/{ratio}.csv'\n",
    "    df = pd.read_csv(df_path, names = col_names)\n",
    "    \n",
    "    # rename columns\n",
    "    df.rename(columns = {'close': f'{ratio}_close', 'volume': f'{ratio}_volume'}, inplace = True)\n",
    "    # set time as index\n",
    "    df.set_index('time', inplace = True)\n",
    "    # select only close price and volume columns\n",
    "    df = df[[f'{ratio}_close', f'{ratio}_volume']]\n",
    "    \n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a binary classification: 1 (buy) vs 0 (hold/sell)\n",
    "def classify(current, future):\n",
    "    if float(future) > float (current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future\n",
      "time                                \n",
      "1528968660      96.580002  96.500000\n",
      "1528968720      96.660004  96.389999\n",
      "1528968780      96.570000  96.519997\n",
      "1528968840      96.500000  96.440002\n",
      "1528968900      96.389999  96.470001\n"
     ]
    }
   ],
   "source": [
    "# Define a new column with future price\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df[[f'{RATIO_TO_PREDICT}_close', 'future']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968660      96.580002  96.500000       0\n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n"
     ]
    }
   ],
   "source": [
    "# Transform future price into a binary target\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "print(main_df[[f'{RATIO_TO_PREDICT}_close', 'future', 'target']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split, normalization, sequence creation and data balancing\n",
    "\n",
    "Notice that since sequences are very close together and are highly correlated, it would be a bad idea to take a random sample to use as a validation/test set, as it would be extremely similar to instances in the training set. Instead, we have to take a whole period (possibly the most recent one) and use it for testing.\n",
    "\n",
    "In this case we'll take the last 5-10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time threshold for train-validation split: 1534922100\n"
     ]
    }
   ],
   "source": [
    "# ensure that time is sorted\n",
    "times = sorted(main_df.index.values)\n",
    "threshold = times[-int(0.05*len(times))]\n",
    "print(f'Time threshold for train-validation split: {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tain-validation split\n",
    "validation_main_df = main_df[(main_df.index >= threshold)]\n",
    "train_main_df = main_df[(main_df.index < threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a preprocessing function that will be applied to both, the training and validation sets.\n",
    "* Transform absolute prices into percentage changes\n",
    "* Normalize data to be in (0,1)\n",
    "* Drop NAs\n",
    "* Create sequences that will be used as features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a preprocessing function\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future', axis = 1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace = True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "            \n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen = SEQ_LEN)\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "            \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    # Balance dataframe\n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    # split into X and y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = preprocess_df(train_main_df)\n",
    "valid_x, valid_y = preprocess_df(validation_main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(128, activation = 'relu', input_shape = (train_x.shape[1:]), return_sequences = True),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    LSTM(128, activation = 'relu', return_sequences = True),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    LSTM(128, activation = 'relu', return_sequences = False),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation = 'sigmoid'),\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay = 1e-6)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'],\n",
    "             )\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = f'logs/{NAME}')\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')) # saves only the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69188 samples, validate on 3062 samples\n",
      "Epoch 1/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.7129 - accuracy: 0.5063WARNING:tensorflow:From /home/lorenzo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/RNN_Final-01-0.488.model/assets\n",
      "69188/69188 [==============================] - 228s 3ms/sample - loss: 0.7129 - accuracy: 0.5063 - val_loss: 0.6944 - val_accuracy: 0.4879\n",
      "Epoch 2/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5155INFO:tensorflow:Assets written to: models/RNN_Final-02-0.492.model/assets\n",
      "69188/69188 [==============================] - 238s 3ms/sample - loss: 0.6936 - accuracy: 0.5155 - val_loss: 0.6941 - val_accuracy: 0.4925\n",
      "Epoch 3/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5210INFO:tensorflow:Assets written to: models/RNN_Final-03-0.486.model/assets\n",
      "69188/69188 [==============================] - 239s 3ms/sample - loss: 0.6922 - accuracy: 0.5210 - val_loss: 0.6939 - val_accuracy: 0.4860\n",
      "Epoch 4/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.5240INFO:tensorflow:Assets written to: models/RNN_Final-04-0.508.model/assets\n",
      "69188/69188 [==============================] - 235s 3ms/sample - loss: 0.6915 - accuracy: 0.5240 - val_loss: 0.6937 - val_accuracy: 0.5078\n",
      "Epoch 5/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6912 - accuracy: 0.5262INFO:tensorflow:Assets written to: models/RNN_Final-05-0.501.model/assets\n",
      "69188/69188 [==============================] - 263s 4ms/sample - loss: 0.6912 - accuracy: 0.5262 - val_loss: 0.6946 - val_accuracy: 0.5013\n",
      "Epoch 6/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.5265INFO:tensorflow:Assets written to: models/RNN_Final-06-0.503.model/assets\n",
      "69188/69188 [==============================] - 246s 4ms/sample - loss: 0.6913 - accuracy: 0.5265 - val_loss: 0.6957 - val_accuracy: 0.5026\n",
      "Epoch 7/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6907 - accuracy: 0.5286INFO:tensorflow:Assets written to: models/RNN_Final-07-0.497.model/assets\n",
      "69188/69188 [==============================] - 248s 4ms/sample - loss: 0.6907 - accuracy: 0.5286 - val_loss: 0.7007 - val_accuracy: 0.4967\n",
      "Epoch 8/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.5226INFO:tensorflow:Assets written to: models/RNN_Final-08-0.498.model/assets\n",
      "69188/69188 [==============================] - 233s 3ms/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6938 - val_accuracy: 0.4977\n",
      "Epoch 9/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6919 - accuracy: 0.5185INFO:tensorflow:Assets written to: models/RNN_Final-09-0.498.model/assets\n",
      "69188/69188 [==============================] - 236s 3ms/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6934 - val_accuracy: 0.4980\n",
      "Epoch 10/10\n",
      "69184/69188 [============================>.] - ETA: 0s - loss: 0.6917 - accuracy: 0.5180INFO:tensorflow:Assets written to: models/RNN_Final-10-0.499.model/assets\n",
      "69188/69188 [==============================] - 237s 3ms/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6936 - val_accuracy: 0.4987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "                   batch_size = BATCH_SIZE,\n",
    "                   epochs = EPOCHS,\n",
    "                   validation_data = (valid_x, valid_y),\n",
    "                   callbacks = [tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
